{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Great Day\n",
    "## Weather Classification Tutorial using Tiny ML on Arduino\n",
    "\n",
    "This notebook demonstrates how to classify structured data (e.g. tabular data in a CSV) and create the necessary files for the Arduino Nano 33 BLE Sense board. We will use Keras to define the model, and feature columns as a bridge to map from columns in a CSV to features used to train the model. This tutorial contains complete code to:\n",
    "\n",
    "- Load a CSV file using Pandas.\n",
    "- Build an input pipeline to batch and shuffle the rows using tf.data.\n",
    "- Map from columns in the CSV to features used to train the model using feature columns.\n",
    "- Build, train, and evaluate a model using Keras.\n",
    "- Convert and encode the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a CSV file using Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp</th>\n",
       "      <th>bright</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27.910000</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29.879999</td>\n",
       "      <td>105.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27.910000</td>\n",
       "      <td>112.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29.889999</td>\n",
       "      <td>117.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27.879999</td>\n",
       "      <td>115.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        temp  bright  target\n",
       "0  27.910000   103.0       1\n",
       "1  29.879999   105.0       1\n",
       "2  27.910000   112.0       1\n",
       "3  29.889999   117.0       1\n",
       "4  27.879999   115.0       1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "great = pd.read_csv(\"data/great.csv\")\n",
    "bad = pd.read_csv(\"data/bad.csv\")\n",
    "\n",
    "great[\"target\"] = 1\n",
    "bad[\"target\"] = 0\n",
    "\n",
    "dataframe = pd.concat([great, bad])\n",
    "\n",
    "# When calling convert() with TFLiteConverter, only accepts float32 or lower for input\n",
    "dataframe[\"temp\"] = pd.to_numeric(dataframe[\"temp\"], downcast='float')\n",
    "dataframe[\"bright\"] = pd.to_numeric(dataframe[\"bright\"], downcast='float')\n",
    "\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 train examples\n",
      "15 validation examples\n",
      "19 test examples\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(dataframe, test_size=0.2)\n",
    "train, val = train_test_split(train, test_size=0.2)\n",
    "print(len(train), 'train examples')\n",
    "print(len(val), 'validation examples')\n",
    "print(len(test), 'test examples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an input pipeline using tf.data\n",
    "**Next, we will wrap the dataframes with tf.data. This will enable us to use feature columns as a bridge to map from the columns in the Pandas dataframe to features used to train the model. If we were working with a very large CSV file (so large that it does not fit into memory), we would use tf.data to read it from disk directly. That is not covered in this tutorial.**\n",
    "\n",
    "**This section may not work if running on a laptop. Increase batch_size to 4 when running on a machine with higher performance.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A utility method to create a tf.data dataset from a Pandas Dataframe\n",
    "def df_to_dataset(dataframe, shuffle=True, batch_size=32, target='target'):\n",
    "    dataframe = dataframe.copy()\n",
    "    labels = dataframe.pop(target)\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "    ds = ds.batch(batch_size)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1 # A small batch sized is used for demonstration purposes\n",
    "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
    "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
    "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Understand the input pipeline**\n",
    "\n",
    "**Now that we have created the input pipeline, let's call it to see the format of the data it returns. We have used a small batch size to keep the output readable.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every feature: ['temp', 'bright']\n",
      "A batch of ages: tf.Tensor([23.84], shape=(1,), dtype=float32)\n",
      "A batch of targets: tf.Tensor([0], shape=(1,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for feature_batch, label_batch in train_ds.take(1):\n",
    "  print('Every feature:', list(feature_batch.keys()))\n",
    "  print('A batch of ages:', feature_batch['temp'])\n",
    "  print('A batch of targets:', label_batch )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can see that the dataset returns a dictionary of column names (from the dataframe) that map to column values from rows in the dataframe.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Demonstrate several types of feature column**\n",
    "\n",
    "**TensorFlow provides many types of feature columns. In this section, we will examine one type of feature column: numerical, and demonstrate how it transforms a column from the dataframe.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use this batch to demonstrate several types of feature columns\n",
    "example_batch = next(iter(train_ds))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A utility method to create a feature column\n",
    "# and to transform a batch of data\n",
    "def demo(feature_column):\n",
    "  feature_layer = layers.DenseFeatures(feature_column)\n",
    "  print(feature_layer(example_batch).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[27.78]]\n"
     ]
    }
   ],
   "source": [
    "age = feature_column.numeric_column(\"temp\")\n",
    "demo(age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose which columns to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = []\n",
    "\n",
    "# numeric cols\n",
    "for header in ['temp', 'bright']:\n",
    "    feature_columns.append(feature_column.numeric_column(header))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_layer = tf.keras.layers.DenseFeatures(feature_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Earlier, we used a small batch size to demonstrate how feature columns worked. We create a new input pipeline with a larger batch size.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
    "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
    "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create, compile, and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:From /Users/kevinwebb/Desktop/ENV/ml-env/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "2/2 [==============================] - 1s 353ms/step - loss: 0.5461 - accuracy: 0.8333 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1304 - accuracy: 1.0000 - val_loss: 0.0604 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0428 - accuracy: 1.0000 - val_loss: 0.0203 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14a83bd90>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.backend.set_floatx('float32')\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  feature_layer,\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_ds,\n",
    "          validation_data=val_ds,\n",
    "          epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Accuracy 1.0\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_ds)\n",
    "print(\"Accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create predictions, print them side by side next to actual values, and plot them for closer examination.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Predictions  Actual\n",
      "0      0.004439       0\n",
      "1      0.007795       0\n",
      "2      0.003131       0\n",
      "3      0.999999       1\n",
      "4      0.003216       0\n",
      "5      0.999996       1\n",
      "6      0.003729       0\n",
      "7      0.004266       0\n",
      "8      1.000000       1\n",
      "9      0.002695       0\n",
      "10     0.010713       0\n",
      "11     0.999999       1\n",
      "12     0.001668       0\n",
      "13     0.004205       0\n",
      "14     0.999995       1\n",
      "15     0.999995       1\n",
      "16     0.999996       1\n",
      "17     0.999993       1\n",
      "18     0.999922       1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use the model to predict the test inputs\n",
    "predictions = model.predict(test_ds)\n",
    "\n",
    "df = pd.DataFrame(predictions, columns = ['Predictions'])\n",
    "df[\"Actual\"] = test[\"target\"].values\n",
    "\n",
    "# print the predictions and the expected ouputs\n",
    "print(df)\n",
    "\n",
    "# Plot the predictions along with to the test data\n",
    "plt.clf()\n",
    "plt.title('Training data predicted vs actual values')\n",
    "plt.plot(test, test[\"target\"], 'b.', label='Actual')\n",
    "plt.plot(test, predictions, 'r.', label='Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the Trained Model to Tensor Flow Lite\n",
    "\n",
    "**The next cell converts the model to TFlite format. The size in bytes of the model is also printed out.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is 69940 bytes\n"
     ]
    }
   ],
   "source": [
    "# Convert the model to the TensorFlow Lite format without quantization\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model to disk\n",
    "open(\"gesture_model.tflite\", \"wb\").write(tflite_model)\n",
    "  \n",
    "import os\n",
    "basic_model_size = os.path.getsize(\"gesture_model.tflite\")\n",
    "print(\"Model is %d bytes\" % basic_model_size)\n",
    "\n",
    "# Warning: Cause: module 'gast' has no attribute 'Num'\n",
    "# Possible Solution: gast==0.2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode the Model in an Arduino Header File \n",
    "\n",
    "**The next cell creates a constant byte array that contains the TFlite model. Import it as a tab with the sketch below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Header file, model.h, is 431,332 bytes.\n",
      "\n",
      "model.h can be found in the data folder.\n"
     ]
    }
   ],
   "source": [
    "!echo \"const unsigned char model[] = {\" > data/model.h\n",
    "!cat gesture_model.tflite | xxd -i      >> data/model.h\n",
    "!echo \"};\"                              >> data/model.h\n",
    "\n",
    "import os\n",
    "model_h_size = os.path.getsize(\"data/model.h\")\n",
    "print(f\"Header file, model.h, is {model_h_size:,} bytes.\")\n",
    "print(\"\\nmodel.h can be found in the data folder.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
